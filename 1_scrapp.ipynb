{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorials I've used\n",
    "- https://towardsdatascience.com/web-scraping-using-selenium-and-beautifulsoup-99195cd70a58\n",
    "- https://www.techbeamers.com/locate-elements-selenium-python/#locate-element-by-id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up selenium and chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juan/Documents/manu/dev/reddit-ml/venv/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: use options instead of chrome_options\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#start selenium driver\n",
    "chrome_options = Options()\n",
    "#disable notifications since it blocks scrolling\n",
    "prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "chrome_options.add_experimental_option(\"prefs\",prefs)\n",
    "#need headless in order to make scrolling work\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap reddit subs\n",
    "I've chosen mostly text-based subs. \n",
    "For example in science, text are more descriptive and the content is mostly a link or a video, so we save the title instead of the content based on length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = ['Vscode','relationships','Entrepreneur','tipofmytongue','science','CasualConversation',]\n",
    "#random.shuffle(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping https://www.reddit.com/r/Vscode\n"
     ]
    }
   ],
   "source": [
    "#will write posts content in a file called posts.csv\n",
    "csv_file = open('posts.csv', 'w')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "#iterate through all wanted subs\n",
    "for sub in subs:\n",
    "    url = \"https://www.reddit.com/r/%s\" % sub\n",
    "    print('scrapping',url)\n",
    "    #open the sub url\n",
    "    driver.get(url)\n",
    "    for i in range(10):\n",
    "        #scroll to bottom many times to load more posts\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        #wait for the page to load\n",
    "        time.sleep(3)\n",
    "    #get all post links\n",
    "    links = set()\n",
    "    #search all links\n",
    "    href_elements = driver.find_elements_by_tag_name('a')\n",
    "    for href_element in href_elements:\n",
    "        link =  href_element.get_attribute(\"href\")\n",
    "        #if comments is in link, means it is a post\n",
    "        if 'comments' in link:\n",
    "            links.add(link)\n",
    "    print('links',len(links))\n",
    "    #go through all links\n",
    "    total = 0\n",
    "    for link in links:\n",
    "        print('accessing',link)\n",
    "        driver.get(link)\n",
    "        #get post title\n",
    "        title_divs = driver.find_elements_by_tag_name('h1')\n",
    "        if len(title_divs) == 0: # is'nt this a real post?\n",
    "            continue\n",
    "        title_div = title_divs[0]\n",
    "        title = title_div.text\n",
    "        #get post content\n",
    "        content_divs = driver.find_elements_by_class_name('RichTextJSON-root')\n",
    "        if len(content_divs) == 0: # is'nt this a real post?\n",
    "            continue\n",
    "        content_div = content_divs[0]\n",
    "        content = content_div.text\n",
    "        #what to save? title or content (we keep the lengthiest)\n",
    "        #some post has a long descriptive text and no content (or video/image content)\n",
    "        #so we keep title instead of post\n",
    "        post_content = max([title, content], key=len)\n",
    "        #if for some reason title and content are empty, skip\n",
    "        if post_content.strip() == '':\n",
    "            continue\n",
    "        #write to csv\n",
    "        post_content = post_content.replace('\\n', ' ')\n",
    "        csv_writer.writerow([sub,post_content])\n",
    "        csv_file.flush()\n",
    "        total += 1\n",
    "        #I don't want to get banned\n",
    "        time.sleep(5)\n",
    "print('scrapped', total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
